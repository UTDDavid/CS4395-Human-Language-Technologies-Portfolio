{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XLr_T55k4yY"
      },
      "source": [
        "# **Assignment 7 - Text Classification**\n",
        "David Nguyen\n",
        "<br><br/>\n",
        "Dataset: https://www.kaggle.com/datasets/deepcontractor/200k-short-texts-for-humor-detection\n",
        "<br><br/>\n",
        "## Describe the data set and what the model should be able to predict.\n",
        "---\n",
        "This dataset classify if a piece of text is funny / a joke or not.\n",
        "\n",
        "\n",
        "\n",
        "The model should be able to predict if a given piece of text is a joke or not.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aG5HAXQrVKJ",
        "outputId": "bab1f49d-5329-4a2b-f494-7d20cbfdfb5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ndavi\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHloxc0-rZgY",
        "outputId": "6b7a5e3d-ff5c-45a2-e18b-166980db1024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rows and columns: (200000, 2)\n",
            "                                                text  humor\n",
            "0  Joe biden rules out 2020 bid: 'guys, i'm not r...      0\n",
            "1  Watch: darvish gave hitter whiplash with slow ...      0\n",
            "2  What do you call a turtle without its shell? d...      1\n",
            "3      5 reasons the 2016 election feels so personal      0\n",
            "4  Pasco police shot mexican migrant from behind,...      0\n",
            "\n",
            "rows and columns: (1000, 2)\n"
          ]
        }
      ],
      "source": [
        "# read in dataset\n",
        "df = pd.read_csv('./dataset.csv', header=0, usecols=[0,1], encoding='latin-1')\n",
        "df[\"humor\"] = df[\"humor\"].astype(int) # turns humor column's T/F to int 1/0\n",
        "print('rows and columns:', df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# truncate dataframe cause collab session crashes\n",
        "df = df.truncate(after=999)\n",
        "print('\\nrows and columns:', df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlIVpHhdsA1U"
      },
      "source": [
        "#  Create a graph showing the distribution of the target classes\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "_INhbEImsC_t",
        "outputId": "c3e6a022-cba0-4e8b-c74d-20d7bc82c2fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x24cf0d38710>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a graph showing the distribution of the target classes\n",
        "import seaborn as sb\n",
        "\n",
        "# set up X and y\n",
        "X = df.text\n",
        "y = df.humor\n",
        "\n",
        "df_y = pd.DataFrame(y,columns=['label'])\n",
        "sb.catplot(x='humor', kind='count', data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aLzR-RxtnS2"
      },
      "source": [
        "#   Divide into train/test. \n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9wC6_SwtYJy",
        "outputId": "9bfe03dd-85a6-44b2-9544-bffe8a21f5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data size:  (781, 2)\n",
            "test data size:  (219, 2)\n"
          ]
        }
      ],
      "source": [
        "# split df into train and test\n",
        "i = np.random.rand(len(df)) < 0.8\n",
        "train = df[i]\n",
        "test = df[~i]\n",
        "print(\"train data size: \", train.shape)\n",
        "print(\"test data size: \", test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uYESPAlscLW",
        "outputId": "40a18be5-cf9e-4265-d3ea-10ed0f3a40a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train shapes: (781, 25000) (781,)\n",
            "test shapes: (219, 25000) (219,)\n",
            "test first five labels: [1 0 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "# set up X and Y\n",
        "num_labels = 2\n",
        "vocab_size = 25000\n",
        "batch_size = 100\n",
        "\n",
        "# fit the tokenizer on the training data\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(train.text)\n",
        "\n",
        "x_train = tokenizer.texts_to_matrix(train.text, mode='tfidf')\n",
        "x_test = tokenizer.texts_to_matrix(test.text, mode='tfidf')\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train.humor)\n",
        "y_train = encoder.transform(train.humor)\n",
        "y_test = encoder.transform(test.humor)\n",
        "\n",
        "# check shape\n",
        "print(\"train shapes:\", x_train.shape, y_train.shape)\n",
        "print(\"test shapes:\", x_test.shape, y_test.shape)\n",
        "print(\"test first five labels:\", y_test[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgDWassxuetD"
      },
      "source": [
        "# Create a sequential model and evaluate on the test data\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekz7eVYyuiX5",
        "outputId": "901a6afa-e178-4679-cb17-b1945115d436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 1s 25ms/step - loss: 0.6973 - accuracy: 0.4729 - val_loss: 0.6948 - val_accuracy: 0.5063\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6794 - accuracy: 0.6624 - val_loss: 0.6882 - val_accuracy: 0.5696\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6624 - accuracy: 0.8148 - val_loss: 0.6812 - val_accuracy: 0.6709\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6403 - accuracy: 0.9017 - val_loss: 0.6717 - val_accuracy: 0.6835\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6104 - accuracy: 0.9487 - val_loss: 0.6585 - val_accuracy: 0.7342\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5714 - accuracy: 0.9630 - val_loss: 0.6416 - val_accuracy: 0.7342\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.5236 - accuracy: 0.9715 - val_loss: 0.6205 - val_accuracy: 0.7722\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4688 - accuracy: 0.9801 - val_loss: 0.5964 - val_accuracy: 0.7975\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.4098 - accuracy: 0.9886 - val_loss: 0.5697 - val_accuracy: 0.7975\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3501 - accuracy: 0.9900 - val_loss: 0.5431 - val_accuracy: 0.7975\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2938 - accuracy: 0.9972 - val_loss: 0.5179 - val_accuracy: 0.7975\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2436 - accuracy: 0.9972 - val_loss: 0.4952 - val_accuracy: 0.8101\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2009 - accuracy: 0.9972 - val_loss: 0.4752 - val_accuracy: 0.8101\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1654 - accuracy: 0.9972 - val_loss: 0.4582 - val_accuracy: 0.8228\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1364 - accuracy: 0.9986 - val_loss: 0.4441 - val_accuracy: 0.8228\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1133 - accuracy: 0.9986 - val_loss: 0.4324 - val_accuracy: 0.8354\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0950 - accuracy: 0.9986 - val_loss: 0.4221 - val_accuracy: 0.8481\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0802 - accuracy: 0.9986 - val_loss: 0.4134 - val_accuracy: 0.8354\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0684 - accuracy: 0.9986 - val_loss: 0.4065 - val_accuracy: 0.8354\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9986 - val_loss: 0.4004 - val_accuracy: 0.8354\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9986 - val_loss: 0.3952 - val_accuracy: 0.8354\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0451 - accuracy: 0.9986 - val_loss: 0.3908 - val_accuracy: 0.8228\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 0.9986 - val_loss: 0.3871 - val_accuracy: 0.8101\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0357 - accuracy: 0.9986 - val_loss: 0.3839 - val_accuracy: 0.8101\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0320 - accuracy: 0.9986 - val_loss: 0.3811 - val_accuracy: 0.7975\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0290 - accuracy: 0.9986 - val_loss: 0.3781 - val_accuracy: 0.7975\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0264 - accuracy: 0.9986 - val_loss: 0.3758 - val_accuracy: 0.7975\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0239 - accuracy: 0.9986 - val_loss: 0.3740 - val_accuracy: 0.7975\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.7848\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.7848\n"
          ]
        }
      ],
      "source": [
        "# fit model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, input_dim=vocab_size, kernel_initializer='normal', activation='relu'))\n",
        "model.add(layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        " \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=30,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf4F2CmCyD_O",
        "outputId": "459dfdc7-49a9-4872-d2ed-41868899735c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8037\n",
            "Accuracy:  0.8036529421806335\n",
            "[0.4449029564857483, 0.8036529421806335]\n"
          ]
        }
      ],
      "source": [
        "# evaluate\n",
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Accuracy: ', score[1])\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G0ZA-C6yJQW",
        "outputId": "9a077040-c849-4a01-80a7-cbfbd24a7dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.9184874 ],\n",
              "       [0.04617033],\n",
              "       [0.70611864],\n",
              "       [0.724794  ],\n",
              "       [0.56553006],\n",
              "       [0.6064179 ],\n",
              "       [0.4050826 ],\n",
              "       [0.9821706 ],\n",
              "       [0.13977507],\n",
              "       [0.050362  ]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get predictions so we can calculate more metrics\n",
        "pred = model.predict(x_test)\n",
        "pred_labels = [1 if p>0.5 else 0 for p in pred]\n",
        "pred[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_VFmLvvyNcn",
        "outputId": "2ec0020e-cb96-40ce-ad12-57732b3aabab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 0, 1, 1, 1, 1, 0, 1, 0, 0]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_xg1hLDyT8D",
        "outputId": "ec48ca67-dff6-4bbf-8a08-93829f622532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy score:  0.8036529680365296\n",
            "precision score:  0.7698412698412699\n",
            "recall score:  0.8738738738738738\n",
            "f1 score:  0.818565400843882\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('accuracy score: ', accuracy_score(y_test, pred_labels))\n",
        "print('precision score: ', precision_score(y_test, pred_labels))\n",
        "print('recall score: ', recall_score(y_test, pred_labels))\n",
        "print('f1 score: ', f1_score(y_test, pred_labels))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a-9rTTYayY9w"
      },
      "source": [
        "# Try a different architecture like RNN, CNN, etc and evaluate on the test data\n",
        "---\n",
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "5waP2v6l2sqP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {
        "id": "VFfuHhQ-2yyT"
      },
      "outputs": [],
      "source": [
        "# build a Sequential model 1D convnet\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Embedding(vocab_size, 100)) \n",
        "model.add(layers.Conv1D(128, 5, activation='relu')) \n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XTA1sK74wUd",
        "outputId": "6b241b98-8d78-4206-982f-591b77066f20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_103\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_86 (Embedding)    (None, None, 100)         2500000   \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, None, 128)         64128     \n",
            "                                                                 \n",
            " global_max_pooling1d_5 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,565,429\n",
            "Trainable params: 2,565,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "id": "bRfqFdS248Zc"
      },
      "outputs": [],
      "source": [
        "# compile\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGUlml-e7cmt",
        "outputId": "024385c4-5aa8-4366-9cde-a2b734f43c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 29s 4s/step - loss: 0.6863 - accuracy: 0.5785 - val_loss: 0.6825 - val_accuracy: 0.6178\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 26s 4s/step - loss: 0.6701 - accuracy: 0.6442 - val_loss: 0.6712 - val_accuracy: 0.6051\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 27s 4s/step - loss: 0.6502 - accuracy: 0.6763 - val_loss: 0.6616 - val_accuracy: 0.6115\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 28s 4s/step - loss: 0.6282 - accuracy: 0.6827 - val_loss: 0.6474 - val_accuracy: 0.5987\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 29s 4s/step - loss: 0.6031 - accuracy: 0.6907 - val_loss: 0.6375 - val_accuracy: 0.6242\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 38s 5s/step - loss: 0.5869 - accuracy: 0.6859 - val_loss: 0.6359 - val_accuracy: 0.6115\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.5692 - accuracy: 0.7163 - val_loss: 0.6196 - val_accuracy: 0.6369\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 31s 4s/step - loss: 0.5462 - accuracy: 0.7356 - val_loss: 0.6078 - val_accuracy: 0.6688\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 30s 4s/step - loss: 0.5316 - accuracy: 0.7436 - val_loss: 0.5991 - val_accuracy: 0.6688\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 30s 4s/step - loss: 0.5200 - accuracy: 0.7436 - val_loss: 0.5909 - val_accuracy: 0.6688\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 356,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 2s 635ms/step - loss: 0.7020 - accuracy: 0.5982\n",
            "Accuracy:  0.5981734991073608\n",
            "[0.70196533203125, 0.5981734991073608]\n"
          ]
        }
      ],
      "source": [
        "# evaluate\n",
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Accuracy: ', score[1])\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 357,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 2s 340ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.6611543 ],\n",
              "       [0.66109216],\n",
              "       [0.675054  ],\n",
              "       [0.83450377],\n",
              "       [0.86205626],\n",
              "       [0.8364781 ],\n",
              "       [0.6485921 ],\n",
              "       [0.82774544],\n",
              "       [0.876327  ],\n",
              "       [0.36247322]], dtype=float32)"
            ]
          },
          "execution_count": 357,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get predictions so we can calculate more metrics\n",
        "pred = model.predict(x_test)\n",
        "pred_labels = [1 if p>0.5 else 0 for p in pred]\n",
        "pred[:10]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]"
            ]
          },
          "execution_count": 358,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy score:  0.5981735159817352\n",
            "precision score:  0.5583756345177665\n",
            "recall score:  0.990990990990991\n",
            "f1 score:  0.7142857142857143\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('accuracy score: ', accuracy_score(y_test, pred_labels))\n",
        "print('precision score: ', precision_score(y_test, pred_labels))\n",
        "print('recall score: ', recall_score(y_test, pred_labels))\n",
        "print('f1 score: ', f1_score(y_test, pred_labels))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Try different embedding approaches and evaluate on the test data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fit model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, input_dim=vocab_size, activation='relu'))\n",
        "model.add(layers.Embedding(vocab_size, 16, input_length=100))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_102\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_219 (Dense)           (None, 64)                1600064   \n",
            "                                                                 \n",
            " embedding_85 (Embedding)    (None, 64, 16)            400000    \n",
            "                                                                 \n",
            " flatten_35 (Flatten)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_220 (Dense)           (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,001,089\n",
            "Trainable params: 2,001,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/kernel:0', 'dense_219/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/kernel:0', 'dense_219/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/kernel:0', 'dense_219/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_219/kernel:0', 'dense_219/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "7/7 [==============================] - 1s 30ms/step - loss: 0.6941 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5032\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6933 - val_accuracy: 0.5032\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6935 - val_accuracy: 0.5032\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6934 - val_accuracy: 0.5032\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6931 - val_accuracy: 0.5032\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5080 - val_loss: 0.6931 - val_accuracy: 0.5032\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.4968\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6941 - accuracy: 0.4920 - val_loss: 0.6934 - val_accuracy: 0.4968\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.4920 - val_loss: 0.6933 - val_accuracy: 0.4968\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.4920 - val_loss: 0.6932 - val_accuracy: 0.5032\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5068\n",
            "Accuracy:  0.5068492889404297\n",
            "[0.6930534243583679, 0.5068492889404297]\n"
          ]
        }
      ],
      "source": [
        "# evaluate\n",
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Accuracy: ', score[1])\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.50697374],\n",
              "       [0.50697374],\n",
              "       [0.50697374],\n",
              "       [0.50697374],\n",
              "       [0.50697374],\n",
              "       [0.50697374],\n",
              "       [0.50697374],\n",
              "       [0.50697374],\n",
              "       [0.50697374],\n",
              "       [0.50697374]], dtype=float32)"
            ]
          },
          "execution_count": 346,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get predictions so we can calculate more metrics\n",
        "pred = model.predict(x_test)\n",
        "pred_labels = [1 if p>0.5 else 0 for p in pred]\n",
        "pred[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "execution_count": 348,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_labels[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy score:  0.5068493150684932\n",
            "precision score:  0.5068493150684932\n",
            "recall score:  1.0\n",
            "f1 score:  0.6727272727272727\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('accuracy score: ', accuracy_score(y_test, pred_labels))\n",
        "print('precision score: ', precision_score(y_test, pred_labels))\n",
        "print('recall score: ', recall_score(y_test, pred_labels))\n",
        "print('f1 score: ', f1_score(y_test, pred_labels))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# analysis of the performance of various approaches\n",
        "---\n",
        "\n",
        "In accuracy, the Sequential model was the best and beat the CNN model and embedding approaches model by a large difference. In order from first to last, the scores for the models were 0.80, 0.60, and 0.51 respectively.\n",
        "In precision, again, the sequential model beat both of the other models by relatively the same large difference/margin as in accuracy as the sequential model got 0.77, while the CNN model had 0.56 and third model had 0.51.\n",
        "In recall score the situation was now different as the CNN model and embedding approaches model was able to get a score of 1, while the Sequential model had 0.87.\n",
        "In the f1 score, the Sequential model won again with a 0.82 and the CNN had 0.71 and the third model had 0.67.\n",
        "The CNN model took the longest to train and still only got second place so it has a large time drawback and even if it were more accurate, it would not be worth it or time efficient.\n",
        "The sequential model was the best for this dataset and the third model was the worst in terms of accuracy but both were fast to train."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
