{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### David Nguyen\n",
        "### dxn180015\n",
        "### Dr. Karen Mazidi\n",
        "### CS 4395.001\n",
        "# <div align=\"center\"> HW 3 - WordNet </div>\n",
        "---\n",
        "\n",
        "# 1. What is WordNet?\n",
        "WordNet is a lexicle database of English words. Words are organized and linked by their lexical & semantic relations or in other words concept and meaning. This database is viewable on a web browser. However, WordNet is more designed to be used by computers for automatic text analysis and artificial intelligence applications.\n",
        "\n",
        "Nouns, verbs, adjectives and adverbs are grouped into sets (synsets) that are each expressing a distinct concept. And synsets are interlinked by semantic and lexical relations. This network of words can then be navigated."
      ],
      "metadata": {
        "id": "dVlpCved-aFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Select a noun (game). Output all synsets of that noun/word"
      ],
      "metadata": {
        "id": "lRqDwFb2T2UF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "15OzUm8J-Zas",
        "outputId": "280e0852-bb8e-4c42-ad8f-00a13db86237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import WordNet and NLTK dependencies\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Get all synsets of the noun 'game' and output all synsets of that noun/word\n",
        "wn.synsets('game')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l5B73qJ3Q19e",
        "outputId": "6abc144e-6edb-49f5-ebe0-fcdf041c3a67"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('game.n.01'),\n",
              " Synset('game.n.02'),\n",
              " Synset('game.n.03'),\n",
              " Synset('game.n.04'),\n",
              " Synset('game.n.05'),\n",
              " Synset('game.n.06'),\n",
              " Synset('game.n.07'),\n",
              " Synset('plot.n.01'),\n",
              " Synset('game.n.09'),\n",
              " Synset('game.n.10'),\n",
              " Synset('game.n.11'),\n",
              " Synset('bet_on.v.01'),\n",
              " Synset('crippled.s.01'),\n",
              " Synset('game.s.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.a. Select one synset (game.n.02) from the list of synsets. Extract its definition, usage examples, and lemmas."
      ],
      "metadata": {
        "id": "UykwSuQZTnXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract its definition\n",
        "wn.synset('game.n.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RTidV9XyRBy4",
        "outputId": "8a584ee0-bd71-4097-9232-04855dd4c2af"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a contest with rules to determine a winner'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract its usage examples\n",
        "wn.synset('game.n.01').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "q-OrO9ZFTHKj",
        "outputId": "dd4bc5ff-a6bf-41aa-a24f-4c3a4d97190b"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you need four people to play this game']"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract its lemmas\n",
        "wn.synset('game.n.01').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fR_OyBLPTHQJ",
        "outputId": "013147e6-2642-48dc-ef2d-2d8f7781c776"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('game.n.01.game')]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.b. Traverse up the WordNet hierarchy as far as you can, outputting the synsets as you go."
      ],
      "metadata": {
        "id": "DrBsERHbUXG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over synsets\n",
        "game_synsets = wn.synsets('game', pos=wn.NOUN)\n",
        "for sense in game_synsets:\n",
        "    lemmas = [l.name() for l in sense.lemmas()]\n",
        "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Xe-0HoqSUyOv",
        "outputId": "09cc78bf-9cad-4486-f8aa-fc8fe53b663b"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: game.n.01(a contest with rules to determine a winner)  \n",
            "\t Lemmas:['game']\n",
            "Synset: game.n.02(a single play of a sport or other contest)  \n",
            "\t Lemmas:['game']\n",
            "Synset: game.n.03(an amusement or pastime)  \n",
            "\t Lemmas:['game']\n",
            "Synset: game.n.04(animal hunted for food or sport)  \n",
            "\t Lemmas:['game']\n",
            "Synset: game.n.05((tennis) a division of play during which one player serves)  \n",
            "\t Lemmas:['game']\n",
            "Synset: game.n.06((games) the score at a particular point or the score needed to win)  \n",
            "\t Lemmas:['game']\n",
            "Synset: game.n.07(the flesh of wild animals that is used for food)  \n",
            "\t Lemmas:['game']\n",
            "Synset: plot.n.01(a secret scheme to do something (especially something underhand or illegal))  \n",
            "\t Lemmas:['plot', 'secret_plan', 'game']\n",
            "Synset: game.n.09(the game equipment needed in order to play a particular game)  \n",
            "\t Lemmas:['game']\n",
            "Synset: game.n.10(your occupation or line of work)  \n",
            "\t Lemmas:['game', 'biz']\n",
            "Synset: game.n.11(frivolous or trifling behavior)  \n",
            "\t Lemmas:['game']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.c. Write a couple of sentences observing the way that WordNet is organized for nouns.\n",
        "\n",
        "WordNet organizes nouns by having the most general concept of that noun/synset at the top of the list. And as you go down the list, the word/noun becomes more specific. And it is also a subset of that concept. \n"
      ],
      "metadata": {
        "id": "hKdva1guVSfc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Output the following (or an empty list if none exist): hypernyms, hyponyms, meronyms, holonyms, antonym. "
      ],
      "metadata": {
        "id": "NOW52Y9-W28D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output all hypernyms of 'game.n.01'\n",
        "noun = wn.synset('game.n.01')\n",
        "noun.hypernyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "M6ItHAXzXKCW",
        "outputId": "d0b49a99-e620-4bd2-de12-d479af7d8fa2"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('activity.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output all hyponyms of 'game.n.01'\n",
        "noun.hyponyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a3YpYVn-XWGw",
        "outputId": "6ae104f4-60f7-4257-f303-76c21ca0523a"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('athletic_game.n.01'),\n",
              " Synset('bowling.n.01'),\n",
              " Synset('card_game.n.01'),\n",
              " Synset('child's_game.n.01'),\n",
              " Synset('curling.n.01'),\n",
              " Synset('game_of_chance.n.01'),\n",
              " Synset('pall-mall.n.01'),\n",
              " Synset('parlor_game.n.01'),\n",
              " Synset('table_game.n.01'),\n",
              " Synset('zero-sum_game.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output all meronyms of 'game.n.01'\n",
        "noun.part_meronyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cfht8ppLXWRL",
        "outputId": "3fefa8fb-6ba2-4256-f1c5-43ad39a2c7f1"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output all holonyms of 'game.n.01'\n",
        "noun.part_holonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wu-QPiKcXWaj",
        "outputId": "0fef5aa2-dfdc-4154-a6ba-faa25a9f12a0"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output all antonym of 'game.n.01'\n",
        "noun.lemmas()[0].antonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a8R6bqo8XX5J",
        "outputId": "809472d8-7ea3-4a5e-a356-375f908de122"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Select a verb. Output all synsets.\n"
      ],
      "metadata": {
        "id": "6HdmyrIYZvAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Get all synsets of the verb 'stretch' and output all synsets of that verb/word\n",
        "verb = wn.synsets('stretch')\n",
        "verb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m56xdSYHaCjk",
        "outputId": "2a3a9d20-f1d8-4143-c86a-dfcd5f648b6b"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('stretch.n.01'),\n",
              " Synset('reach.n.03'),\n",
              " Synset('stretch.n.03'),\n",
              " Synset('stretch.n.04'),\n",
              " Synset('stretch.n.05'),\n",
              " Synset('stretch.n.06'),\n",
              " Synset('stretch.n.07'),\n",
              " Synset('stretch.v.01'),\n",
              " Synset('stretch.v.02'),\n",
              " Synset('unfold.v.03'),\n",
              " Synset('stretch.v.04'),\n",
              " Synset('elongate.v.01'),\n",
              " Synset('stretch.v.06'),\n",
              " Synset('stretch.v.07'),\n",
              " Synset('stretch.v.08'),\n",
              " Synset('load.v.05'),\n",
              " Synset('extend.v.17'),\n",
              " Synset('stretch.v.11'),\n",
              " Synset('stretch.s.01'),\n",
              " Synset('stretch.s.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Select one synset (game.n.02) from the list of synsets. Extract its definition, usage examples, and lemmas."
      ],
      "metadata": {
        "id": "8X76Lt-ZaiHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract its definition\n",
        "wn.synset('stretch.v.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gjBZnBPcag2n",
        "outputId": "0ab44f3b-14d3-49a2-f7af-37950615b82a"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'occupy a large, elongated area'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract its usage examples\n",
        "wn.synset('stretch.v.01').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lvHgSBXzbDj5",
        "outputId": "eafb8023-4457-4b57-9270-a01788b11bdf"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The park stretched beneath the train line']"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract its lemmas\n",
        "wn.synset('stretch.v.01').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_A9h7pxJbF1N",
        "outputId": "1df37f79-88fc-4225-c008-ca9cdbc265eb"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('stretch.v.01.stretch'), Lemma('stretch.v.01.stretch_along')]"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.b. Traverse up the WordNet hierarchy as far as you can, outputting the synsets as you go."
      ],
      "metadata": {
        "id": "eXhAb0YDbOnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate over synsets\n",
        "stretch_synsets = wn.synsets('stretch', pos=wn.VERB)\n",
        "for sense in stretch_synsets:\n",
        "    lemmas = [l.name() for l in sense.lemmas()]\n",
        "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "18dj3xBAbSH5",
        "outputId": "d5266953-bcd0-4b3a-dcdb-54ef72618d54"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: stretch.v.01(occupy a large, elongated area)  \n",
            "\t Lemmas:['stretch', 'stretch_along']\n",
            "Synset: stretch.v.02(extend one's limbs or muscles, or the entire body)  \n",
            "\t Lemmas:['stretch', 'extend']\n",
            "Synset: unfold.v.03(extend or stretch out to a greater or the full length)  \n",
            "\t Lemmas:['unfold', 'stretch', 'stretch_out', 'extend']\n",
            "Synset: stretch.v.04(become longer by being stretched and pulled)  \n",
            "\t Lemmas:['stretch']\n",
            "Synset: elongate.v.01(make long or longer by pulling and stretching)  \n",
            "\t Lemmas:['elongate', 'stretch']\n",
            "Synset: stretch.v.06(lie down comfortably)  \n",
            "\t Lemmas:['stretch', 'stretch_out']\n",
            "Synset: stretch.v.07(pull in opposite directions)  \n",
            "\t Lemmas:['stretch']\n",
            "Synset: stretch.v.08(extend the scope or meaning of; often unduly)  \n",
            "\t Lemmas:['stretch']\n",
            "Synset: load.v.05(corrupt, debase, or make impure by adding a foreign or inferior substance; often by replacing valuable ingredients with inferior ones)  \n",
            "\t Lemmas:['load', 'adulterate', 'stretch', 'dilute', 'debase']\n",
            "Synset: extend.v.17(increase in quantity or bulk by adding a cheaper substance)  \n",
            "\t Lemmas:['extend', 'stretch']\n",
            "Synset: stretch.v.11(extend one's body or limbs)  \n",
            "\t Lemmas:['stretch', 'stretch_out']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.c. Write a couple of sentences observing the way that WordNet is organized for verbs.\n",
        "\n",
        "Just like in 3c or for nouns, WordNet organizes verbs by having the most general concept of that noun/synset at the top of the list. And as you go down the list, the word/noun becomes more specific. And it is also a subset of that concept. \n"
      ],
      "metadata": {
        "id": "vpBbTGnzbxZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Use morphy to find as many different forms of the word as you can. \n"
      ],
      "metadata": {
        "id": "zM5Y4PjJcAO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('stretch',wn.VERB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "599fgYlkcH51",
        "outputId": "d86efe05-fbae-47fa-f183-1914a471265e"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stretch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.a. Select two words that you think might be similar. Find the specific synsets you are interested in. \n"
      ],
      "metadata": {
        "id": "kTUpqkHdcHLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find 2 similar words\n",
        "word1 = wn.synsets('rest')\n",
        "word2 = wn.synsets('relax')\n",
        "print(word1)\n",
        "print()\n",
        "print(word2)\n",
        "\n",
        "# Find 2 specific synsets\n",
        "word1_synset = wn.synset('rest.v.01')\n",
        "word2_synset = wn.synset('relax.v.01')\n",
        "print()\n",
        "print('rest.v.01')\n",
        "print('relax.v.01')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bnnjZWn_cxJ1",
        "outputId": "ec4d83a9-179a-4278-efc9-ec1824972a20"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('remainder.n.01'), Synset('rest.n.02'), Synset('respite.n.04'), Synset('rest.n.04'), Synset('rest.n.05'), Synset('rest.n.06'), Synset('rest.n.07'), Synset('rest.v.01'), Synset('rest.v.02'), Synset('rest.v.03'), Synset('lie.v.06'), Synset('rest.v.05'), Synset('stay.v.01'), Synset('rest.v.07'), Synset('rest.v.08'), Synset('perch.v.01'), Synset('pillow.v.01'), Synset('rest.v.11')]\n",
            "\n",
            "[Synset('relax.v.01'), Synset('relax.v.02'), Synset('loosen.v.07'), Synset('relax.v.04'), Synset('relax.v.05'), Synset('relax.v.06'), Synset('relax.v.07'), Synset('slack.v.04')]\n",
            "\n",
            "rest.v.01\n",
            "relax.v.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.b. Run the Wu-Palmer similarity metric and the Lesk algorithm."
      ],
      "metadata": {
        "id": "S1NLy_xWcxgU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Wu-Palmer similarity metric\n",
        "wn.wup_similarity(word1_synset, word2_synset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6WiKZNi8c6kM",
        "outputId": "0a2fe7b7-900f-471d-e164-36fcf51788a1"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2857142857142857"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Lesk algorithm\n",
        "from nltk.wsd import lesk\n",
        "\n",
        "# Look at the definitions for 'rest'\n",
        "for ss in wn.synsets('rest'):\n",
        "    print(ss, ss.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4MLbmqxDeUhR",
        "outputId": "3b1f150d-0c34-415b-f0d5-2a0a5cbd0483"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('remainder.n.01') something left after other parts have been taken away\n",
            "Synset('rest.n.02') freedom from activity (work or strain or responsibility)\n",
            "Synset('respite.n.04') a pause for relaxation\n",
            "Synset('rest.n.04') a state of inaction\n",
            "Synset('rest.n.05') euphemisms for death (based on an analogy between lying in a bed and in a tomb)\n",
            "Synset('rest.n.06') a support on which things can be put\n",
            "Synset('rest.n.07') a musical notation indicating a silence of a specified duration\n",
            "Synset('rest.v.01') not move; be in a resting position\n",
            "Synset('rest.v.02') take a short break from one's activities in order to relax\n",
            "Synset('rest.v.03') give a rest to\n",
            "Synset('lie.v.06') have a place in relation to something else\n",
            "Synset('rest.v.05') be at rest\n",
            "Synset('stay.v.01') stay the same; remain in a certain state\n",
            "Synset('rest.v.07') be inherent or innate in\n",
            "Synset('rest.v.08') put something in a resting position, as for support or steadying\n",
            "Synset('perch.v.01') sit, as on a branch\n",
            "Synset('pillow.v.01') rest on or as if on a pillow\n",
            "Synset('rest.v.11') be inactive, refrain from acting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Lesk algorithm\n",
        "print('The ball was at rest.')\n",
        "sent = ['The', 'ball', 'was', 'at', 'rest', '.']\n",
        "print(lesk(sent, 'rest', 'v'), '\\n')\n",
        "\n",
        "print(\"The game was put to rest on my bed.\")\n",
        "sent = ['The', 'game', 'was', 'put', 'to', 'rest', 'on', 'my', 'bed', '.']\n",
        "print(lesk(sent, 'rest', 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wFoYWlaMhKYH",
        "outputId": "ca61478e-2a77-4ecc-f2ab-406ca8e90ce1"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ball was at rest.\n",
            "Synset('rest.v.05') \n",
            "\n",
            "The game was put to rest on my bed.\n",
            "Synset('rest.v.03')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.c. Write a couple of sentences with your observations.\n",
        "The Wu-Palmer similarity metric is a very cool way to see how similar 2 words are to each other. I was suprised how rest and relax had a low score.\n",
        "\n",
        "And the Lesk algorithm was also interresting to use to see which definition a word was used in a sentence. I used multiple forms of rest in a sentence and the lesk alforithmn gave me the correct definition."
      ],
      "metadata": {
        "id": "a4TA31j0c3Qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.a. Write a couple of sentences about SentiWordNet, describing its functionality and possible use cases. \n",
        "\n",
        "SentiWordNet is a lexical resource that's is based on WordNet. It's function is to calculae and assign each synset 3 \"sentiment scores\". They are positivity, negativity, and objectivity. \n",
        "\n",
        "Thus, this resource has many possible use cases with sentiment analysis on subjective text and see if people are viewing somethign positively, negatively, or neutrally. This can be useful for search engines or summarizing/analyzing product reviews, blog posts, books, tweets, and forum posts."
      ],
      "metadata": {
        "id": "GzKbWCJfi0Bb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.b. Select an emotionally charged word. Find its senti-synsets and output the polarity scores for each word. "
      ],
      "metadata": {
        "id": "vMRCkYdNk5KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import SentiWordNet\n",
        "nltk.download('sentiwordnet')\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n",
        "# Select emotionally charged word\n",
        "print(wn.synsets('hate'))\n",
        "print()\n",
        "\n",
        "# iterate over synsets\n",
        "hate_synsets = wn.synsets('hate')\n",
        "for sense in hate_synsets:\n",
        "    lemmas = [l.name() for l in sense.lemmas()]\n",
        "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))\n",
        "print()\n",
        "\n",
        "# Find its senti-synsets and output the polarity scores for each word\n",
        "senti_synsets = list(swn.senti_synsets('hate'))\n",
        "\n",
        "for i in senti_synsets:\n",
        "  print(i)\n",
        "  print(\"Positive score = \", i.pos_score())\n",
        "  print(\"Negative score = \", i.neg_score())\n",
        "  print(\"Objective score = \", i.obj_score())\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Np953wBHlFx7",
        "outputId": "27c1e903-3143-4dbf-cba6-b840c2e63705"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('hate.n.01'), Synset('hate.v.01')]\n",
            "\n",
            "Synset: hate.n.01(the emotion of intense dislike; a feeling of dislike so strong that it demands action)  \n",
            "\t Lemmas:['hate', 'hatred']\n",
            "Synset: hate.v.01(dislike intensely; feel antipathy or aversion towards)  \n",
            "\t Lemmas:['hate', 'detest']\n",
            "\n",
            "<hate.n.01: PosScore=0.125 NegScore=0.375>\n",
            "Positive score =  0.125\n",
            "Negative score =  0.375\n",
            "Objective score =  0.5\n",
            "\n",
            "<hate.v.01: PosScore=0.0 NegScore=0.75>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.75\n",
            "Objective score =  0.25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.c. Make up a sentence. Output the polarity for each word in the sentence."
      ],
      "metadata": {
        "id": "FQSMjxOllEyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make up a sentence\n",
        "sent = 'HP has the worst customer service I have ever seen'\n",
        "print(sent + \"\\n\")\n",
        "\n",
        "neg = 0\n",
        "pos = 0\n",
        "tokens = sent.split()\n",
        "for token in tokens:\n",
        "    syn_list = list(swn.senti_synsets(token))\n",
        "    if syn_list:\n",
        "        syn = syn_list[0]\n",
        "        neg += syn.neg_score()\n",
        "        pos += syn.pos_score()\n",
        "    \n",
        "print(\"neg\\tpos counts\")\n",
        "print(neg, '\\t', pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D4LmAuggpB2-",
        "outputId": "effb9cd9-ca04-401a-80bf-404584463729"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HP has the worst customer service I have ever seen\n",
            "\n",
            "neg\tpos counts\n",
            "1.0 \t 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9.d. Write a couple of sentences about your observations of the scores and the utility of knowing these scores in an NLP application.\n",
        "\n",
        "The score shows that my sentence has a 100% negative sentiment, which is correct as that sentence is meant to be from an angry customer of HP.\n",
        "\n",
        "This can be helpful very in NLP applications where one wants to analyze the sentiments from the comments/posts of users (be it an comment, review, feedback, etc.) from a forum, form, book, article, etc. With this analysis, one can determine how a user or post may be emotionally negative, positive, helpful, dangerous, or even harmful. And the results can then be used to possibly improve your product based on feedback, implement changes, ban/delete/report users/posts, etc.\n",
        "\n"
      ],
      "metadata": {
        "id": "jJW5QcQUowWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.a. Write a couple of sentences about what a collocation is. \n",
        "\n",
        "A collocation is a set of 2 or more words that are frequently used together to form a meaning of a thing or concept. When used together, those words means differently or something greater than the meaning of each indiviual word. Examples of collocations are 'a quick meal', 'hard disk', 'a quick shower'. While a set of words like 'a fast shower' sounds unnatural and is not collocation."
      ],
      "metadata": {
        "id": "1KGn0hVDreJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.b. Output collocations for text4, the Inaugural corpus."
      ],
      "metadata": {
        "id": "rzSywZTvr9jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import text4\n",
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')\n",
        "from nltk.book import *\n",
        "text4\n",
        "\n",
        "# Output collocations for text4, the Inaugural corpus\n",
        "print()\n",
        "text4.collocations()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "de1W8_-lsJqK",
        "outputId": "240dcfb2-e3cc-4661-85ca-a2cbd51a2627"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.c. Select one of the collocations identified by NLTK. Calculate mutual information."
      ],
      "metadata": {
        "id": "704Fvt1psB3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import math\n",
        "import math\n",
        "\n",
        "# Print section of text4\n",
        "text = ' '.join(text4.tokens)\n",
        "print(text[:150], '...\\n')\n",
        "\n",
        "# Select a collocations identified by NLTK \n",
        "# and calculate Mutual info - 'Federal Government'\n",
        "import math\n",
        "vocab = len(set(text6))\n",
        "hg = text.count('Federal Government')/vocab\n",
        "print(\"p(Federal Government) = \",hg )\n",
        "\n",
        "h = text.count('Federal')/vocab\n",
        "print(\"p(Federal) = \", h)\n",
        "\n",
        "g = text.count('Government')/vocab\n",
        "print('p(Government) = ', g)\n",
        "\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)\n",
        "print()\n",
        "\n",
        "# Select a collocations identified by NLTK \n",
        "# and calculate Mutual info - 'foreign nations'\n",
        "import math\n",
        "vocab = len(set(text6))\n",
        "hg = text.count('foreign nations')/vocab\n",
        "print(\"p(foreign nations) = \",hg )\n",
        "\n",
        "h = text.count('foreign')/vocab\n",
        "print(\"p(foreign) = \", h)\n",
        "\n",
        "g = text.count('nations')/vocab\n",
        "print('p(nations) = ', g)\n",
        "\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eyGgZlt2sJKh",
        "outputId": "8641082c-a77f-4406-e1ac-5ec979e56b84"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fellow - Citizens of the Senate and of the House of Representatives : Among the vicissitudes incident to life no event could have filled me with great ...\n",
            "\n",
            "p(Federal Government) =  0.014773776546629732\n",
            "p(Federal) =  0.030009233610341645\n",
            "p(Government) =  0.15604801477377656\n",
            "pmi =  1.6575702782976882\n",
            "\n",
            "p(foreign nations) =  0.006925207756232687\n",
            "p(foreign) =  0.04755309325946445\n",
            "p(nations) =  0.09464450600184672\n",
            "pmi =  0.6217274965281813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.d. Write commentary on the results of the mutual information formula and your interpretation. \n",
        "\n",
        "When calculating the PMI or Pointwise Mutual Information for \"Federal Government\" and \"foreign nations\", the results were 1.6575702782976882 and 0.6217274965281813 respectively. Thus, \"Federal Government\" is more likey to be a collocation than \"foreign nations\".\n",
        "\n",
        "We can see that \"Government\" occurs more frequently than \"Federal\" or \"Federal Government\". While \"Federal Government\" occurs more than \"Federal\". We can also see that \"nations\" occurs more frequently than \"foreign\" or \"foreign nations\". While \"foreign\" occurs more than \"foreign nations\". "
      ],
      "metadata": {
        "id": "jRc9sKxVsGw5"
      }
    }
  ]
}